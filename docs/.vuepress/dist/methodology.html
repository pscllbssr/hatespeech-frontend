<!DOCTYPE html>
<html lang="de-CH">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Methodik Hate Speech Classifier | Der Hass im Netz</title>
    <meta name="description" content="Ein Artikel über den Hass im Netz und die Frage, ob uns Maschinen dabei helfen können, ihn zu bekämpfen.">
    
    
    <link rel="preload" href="/der-hass-im-netz/assets/css/0.styles.5b6b8e92.css" as="style"><link rel="preload" href="/der-hass-im-netz/assets/js/app.9716dcac.js" as="script"><link rel="preload" href="/der-hass-im-netz/assets/js/5.674916e7.js" as="script"><link rel="preload" href="/der-hass-im-netz/assets/js/6.7f7e1b88.js" as="script"><link rel="prefetch" href="/der-hass-im-netz/assets/js/2.9d04385a.js"><link rel="prefetch" href="/der-hass-im-netz/assets/js/3.96067ce1.js"><link rel="prefetch" href="/der-hass-im-netz/assets/js/4.9934da44.js"><link rel="prefetch" href="/der-hass-im-netz/assets/js/7.b3280048.js"><link rel="prefetch" href="/der-hass-im-netz/assets/js/8.cd9ecedd.js">
    <link rel="stylesheet" href="/der-hass-im-netz/assets/css/0.styles.5b6b8e92.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div><div parallax="" class="theme-header"><header><h1>Methodik Hate Speech Classifier</h1></header> <div data-offset="0.1" class="parallax bubble-1"></div> <div data-offset="0.2" class="parallax bubble-2"></div> <div data-offset="0.3" class="parallax bubble-3"></div> <div data-offset="0.4" class="parallax bubble-4"></div></div> <div class="theme-container"><div class="content custom"><p>Ich habe ein Machine Learning Modell entwickelt, das Hate Speech in Textnachrichten erkennen kann, einen Hate Speech Classifier. Der ganze Programmiercode für das entwickelte Modell kann auf Github abgerufen werden.</p> <p><a href="https://github.com/pscllbssr/hatespeech-ml" target="_blank" rel="noopener noreferrer">github.com/pscllbssr/hatespeech-ml<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>Nachfolgend eine Beschreibung, wie ich konkret vorgegangen bin, um das Modell zu entwickeln.</p> <h2 id="datenbeschaffung-und-aufbereitung"><a href="#datenbeschaffung-und-aufbereitung" aria-hidden="true" class="header-anchor"></a> Datenbeschaffung und -aufbereitung</h2> <p>Damit das Modell lernen konnte, Hasskommentare zu erkennen, benötigte ich zuerst genügend Trainingsdaten. Also Beispiele von Hasskommenteren, aber auch Gegenbeispiele, Kommentare frei von Hass.</p> <p>Zu diesem Zweck wollte ich ursprünglich Hasskommentare verwenden, bei denen es zu einer Verurteilung kam. Ein solcher Datensatz war aber schwer zu beschaffen und in der Summe zu wenige Beispiele, um Machine Learning damit zu betreiben. Ein anderer Ansatz war, Kommentarspalten aus Online-Medienangeboten oder gesammelte Hasskommentare von Anti-Diskriminierungsstellen zu verwenden. Diese waren aber meist zu wenig strukturiert oder schlicht nicht zugänglich.</p> <p>Schlussendlich griff ich auf drei Datensätze aus der Forschung zurück, die ich zu einem grossen Datensatz kombinierte. Die verwendeten Datensätze:</p> <ul><li>Datensatz des Graduiertenkollegs «Nutzerzentrierte Soziale Medien» der Universität Duisburg-Essen: <a href="https://github.com/UCSM-DUE/IWG_hatespeech_public" target="_blank" rel="noopener noreferrer">Link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Datensatz aus einer Arbeit von Uwe Bretschneider und Ralf Peters, Martin-Luther-Universität Halle-Wittenberg: <a href="http://www.ub-web.de/research/" target="_blank" rel="noopener noreferrer">Link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Polly-Korpus von Tom De Smedt (Universität Antwerpen) und Sylvia Jaki (Universität Hildesheim): <a href="https://docs.google.com/spreadsheets/d/1c5peNMjt24U0FcEMSj8gD_JjzumqXTWbPWa_yb2nNt0/edit#gid=2031183870" target="_blank" rel="noopener noreferrer">Link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <p>Diese Datensätze musste ich zuerst in die gleiche technische und inhaltliche Form bringen, da verschiedene Speicherformate und unterschiedliche Annotationsschemen verwendet wurden. <a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/2_Feature_Engineering/export/combined_polly_bretschneider_iwg.xlsx" target="_blank" rel="noopener noreferrer">Im kombinierten Datensatz<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> sind der Rohtext des Kommentars, die durchschnittliche Einschätzung aller Experten (Zahl zwischen 0 und 1), sowie davon abgeleitet eine binäre Einschätzung des Kommentars (Hasskommentar ja/nein) enthalten. Zudem habe ich Texte unter 50 Zeichen (schwer zu verstehen) und Texte über 300 Zeichen (maximale Tweet Länge: 280 Zeichen) herausgefiltert, um es der Maschine einfacher zu machen.</p> <p>Der Code dafür findet sich in den einzelnen Notebooks:</p> <ul><li><a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/2_Feature_Engineering/8%20combine%20IWG%2C%20Bretschneider%20and%20polly%20subset.ipynb" target="_blank" rel="noopener noreferrer">Kombination der Datensätze<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Umwandlung der einzelnen Datensätze (Links)</li></ul> <h2 id="feature-engineering"><a href="#feature-engineering" aria-hidden="true" class="header-anchor"></a> Feature-Engineering</h2> <p>Ein zentraler Punkt beim Machine Learning ist das sogenannte «Feature-Engineering», also das Auswählen und Aufbereiten verschiedener Merkmale eines Datensatzes. Als erstes musste ich die Texte zur weiteren Verarbeitung durch die Maschine vorbereiten.</p> <p>In einem ersten Schritt anonymisiere ich Benutzernamen, falls das nicht bereits in den Quell-Datensätzen geschehen ist. Zudem werden Elemente entfernt, die nichts direkt mit dem untersuchten Text zu tun haben, beispielsweise Links oder plattformspezifische Ausdrücke wie RT (Hinweis auf einen Retweet bei Twitter). Diese Elemente würden ansonsten das Resultat verzerren.</p> <p>In einem weiteren Schritt entferne ich «Stopwords» aus dem Text. Stopwords sind Wörter, die in einer Sprache oft vorkommen und nicht wirklich zur Aussage eines Textes beitragen. (Stopwords-Erklärung). Anschliessend benutzte ich einen <a href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" target="_blank" rel="noopener noreferrer">Lemmatizer<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, um Wörter auf ihre Grundform zu reduzieren. Konjugierte Verben werden so als dasselbe Wort angesehen, also beispielsweise «bin», «bist» und «sind» werden in dieselbe Grundform «sein» umgewandelt.</p> <p><a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/0_common/model_helpers.py" target="_blank" rel="noopener noreferrer">Code der Umwandlung<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>Der wichtigste Schritt in der maschinellen Sprachverarbeitung ist das Vektorisieren, also die Umwandlung von Buchstaben in Zahlen. Dies ist nötig, weil Computer nicht mit Worten oder Buchstaben rechnen, sondern mit Zahlen. Dafür gibt es verschiedene Methoden. Während der Entwicklung meines Machine Learning Modells habe ich verschiedene Verfahren ausprobiert. Schlussendlich habe ich mit einem simplen <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" target="_blank" rel="noopener noreferrer">CountVectorizer<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> auf der Basis von Wortteilen die besten Resultate erzielt. Diese Erfahrung findet sich auch in der Wissenschaft wieder, beispielsweise bei Schmidt und Wiegand (2017, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" target="_blank" rel="noopener noreferrer">Link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>). Wortteile, anstelle von ganzen Wörter, bringen eine gewisse Toleranz gegenüber Rechtschreibefehlern mit sich, was bei Hasskommentaren nicht unrelevant ist.</p> <p>“Fairly generic features, such as bag of words or embeddings, systematically yield reasonable classification performance. Character-level approaches work better than token-level approaches» https://www.aclweb.org/anthology/W17-1101</p> <p>«Mehdad and Tetreault (2016) systematically compare character n-gram features with token n-grams for hate speech detection, and find that character n-grams prove to be more predictive than token n-grams»  https://www.aclweb.org/anthology/W17-1101</p> <p>«Hate speech and sentiment analysis are closely related, and it is safe to assume that usually negative sentiment pertains to a hate speech message» https://www.aclweb.org/anthology/W17-1101
konnte ich in meinem Beispiel, mit einem Korpus getestet, nicht bestätigen</p> <h2 id="auswahl-der-algorithmen-und-modell-training"><a href="#auswahl-der-algorithmen-und-modell-training" aria-hidden="true" class="header-anchor"></a> Auswahl der Algorithmen und Modell-Training</h2> <p>finales Modell: Link</p> <p>API und Modell Open Source - gerne weiter verwenden</p></div></div></div></div>
    <script src="/der-hass-im-netz/assets/js/app.9716dcac.js" defer></script><script src="/der-hass-im-netz/assets/js/5.674916e7.js" defer></script><script src="/der-hass-im-netz/assets/js/6.7f7e1b88.js" defer></script>
  </body>
</html>
