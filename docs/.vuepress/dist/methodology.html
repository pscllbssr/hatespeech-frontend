<!DOCTYPE html>
<html lang="de-CH">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Methodik Hate Speech Classifier | Der Hass im Netz</title>
    <meta name="description" content="Ein Artikel über den Hass im Netz und die Frage, ob uns Maschinen dabei helfen können, ihn zu bekämpfen.">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="icon" href="/der-hass-im-netz/favicon.ico">
    
    <link rel="preload" href="/der-hass-im-netz/assets/css/0.styles.6f17d4da.css" as="style"><link rel="preload" href="/der-hass-im-netz/assets/js/app.12741693.js" as="script"><link rel="preload" href="/der-hass-im-netz/assets/js/2.71482812.js" as="script"><link rel="preload" href="/der-hass-im-netz/assets/js/7.5ffeac9c.js" as="script"><link rel="prefetch" href="/der-hass-im-netz/assets/js/3.8d35b793.js"><link rel="prefetch" href="/der-hass-im-netz/assets/js/4.16f6adc9.js"><link rel="prefetch" href="/der-hass-im-netz/assets/js/5.b034e766.js"><link rel="prefetch" href="/der-hass-im-netz/assets/js/6.3421ebb0.js"><link rel="prefetch" href="/der-hass-im-netz/assets/js/8.4eeea7fb.js"><link rel="prefetch" href="/der-hass-im-netz/assets/js/9.263fe1fd.js">
    <link rel="stylesheet" href="/der-hass-im-netz/assets/css/0.styles.6f17d4da.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div><div parallax="" class="theme-header"><header><div><h1>Methodik Hate Speech Classifier</h1> <div class="sans-serif theme-header__meta">9. August 2019 - Pascal Albisser</div></div></header> <div data-offset="0.3" class="parallax bubble-3"></div> <div data-offset="0.2" class="parallax bubble-2"></div> <div data-offset="0.1" class="parallax bubble-1"></div></div> <div class="theme-container"><div class="content custom"><p><em>Für den Artikel «<a href="/der-hass-im-netz/" class="router-link-active">Der Hass im Netz</a>» entwickelte ich ein Machine Learning Modell, das Hate Speech in Textnachrichten erkennen kann. Nachfolgend eine Beschreibung, wie ich konkret vorgegangen bin, um das Modell zu entwickeln. Der ganze Programmiercode kann auf <a href="https://github.com/pscllbssr/hatespeech-ml" target="_blank" rel="noopener noreferrer">Github<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> abgerufen werden.</em></p> <h2 id="datenbeschaffung-und-aufbereitung"><a href="#datenbeschaffung-und-aufbereitung" aria-hidden="true" class="header-anchor"></a> Datenbeschaffung und -aufbereitung</h2> <p>Damit das Modell lernen konnte, Hasskommentare zu erkennen, benötigte ich zuerst genügend Trainingsdaten. Also einen Haufen Hasskommentare und neutrale Gegenbeispiele.</p> <p>Zu diesem Zweck wollte ich ursprünglich Hasskommentare verwenden, bei denen es zu einer Verurteilung kam. Ein solcher Datensatz war aber schwer zu beschaffen und enthielt in der Summe zu wenige Beispiele, um Machine Learning damit zu betreiben. Ein anderer Ansatz war, Kommentarspalten aus Online-Medienangeboten oder gesammelte Hasskommentare von Anti-Diskriminierungsstellen zu verwenden. Diese waren aber meist zu wenig strukturiert oder schlicht nicht zugänglich.</p> <p>Schlussendlich griff ich auf drei Datensätze aus der Forschung zurück, die ich zu einem grossen Datensatz kombinierte. Die verwendeten Datensätze:</p> <ul><li>Datensatz des Graduiertenkollegs «Nutzerzentrierte Soziale Medien» der Universität Duisburg-Essen: <a href="https://github.com/UCSM-DUE/IWG_hatespeech_public" target="_blank" rel="noopener noreferrer">Link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Datensatz aus einer Arbeit von Uwe Bretschneider und Ralf Peters, Martin-Luther-Universität Halle-Wittenberg: <a href="http://www.ub-web.de/research/" target="_blank" rel="noopener noreferrer">Link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>Polly-Korpus von Tom De Smedt (Universität Antwerpen) und Sylvia Jaki (Universität Hildesheim): <a href="https://docs.google.com/spreadsheets/d/1c5peNMjt24U0FcEMSj8gD_JjzumqXTWbPWa_yb2nNt0/edit#gid=2031183870" target="_blank" rel="noopener noreferrer">Link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <p>Diese Datensätze musste ich zuerst in die gleiche technische und inhaltliche Form bringen, da sie in verschiedenen Speicherformaten und unterschiedlichen Annotationsschemen vorlagen. <a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/2_Feature_Engineering/export/combined_polly_bretschneider_iwg.xlsx" target="_blank" rel="noopener noreferrer">Im kombinierten Datensatz<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> sind der Rohtext des Kommentars, die durchschnittliche Einschätzung aller Experten (Zahl zwischen 0 und 1), sowie davon abgeleitet eine binäre Einschätzung des Kommentars (Hasskommentar ja/nein) enthalten. Zudem habe ich Texte unter 50 Zeichen (schwer zu kontextualisieren) und Texte über 300 Zeichen (maximale Tweet Länge: 280 Zeichen) herausgefiltert, um es der Maschine einfacher zu machen.</p> <p>Der Code dafür findet sich in den einzelnen Notebooks:</p> <ul><li><a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/2_Feature_Engineering/8%20combine%20IWG%2C%20Bretschneider%20and%20polly%20subset.ipynb" target="_blank" rel="noopener noreferrer">Kombination der Datensätze<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/1_Data_Cleaning/Dataset_Facebook_Bretschneider_Peters_2016/Preparing%20from%20MySQL%20source.ipynb" target="_blank" rel="noopener noreferrer">Aufbereitung<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> und <a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/2_Feature_Engineering/1%20Normalize%20Breitschneider%20Peters%20Facebook%20Hate%20Speech.ipynb" target="_blank" rel="noopener noreferrer">Umrechnung<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> der Datensatzes von Bretschneider/Peters</li> <li><a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/2_Feature_Engineering/2%20Normalize%20IWG%20twitter%20dataset%20on%20refugees.ipynb" target="_blank" rel="noopener noreferrer">Aufbereitung<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> des IWG-Datensatzes</li> <li><a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/1_Data_Cleaning/Polly_corpus/cleanup.ipynb" target="_blank" rel="noopener noreferrer">Aufbereitung<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> der Beispiele aus dem Polly-Korpus</li></ul> <h2 id="feature-engineering"><a href="#feature-engineering" aria-hidden="true" class="header-anchor"></a> Feature-Engineering</h2> <p>Ein zentraler Punkt beim Machine Learning ist das sogenannte «Feature-Engineering», also das Auswählen und Aufbereiten verschiedener Merkmale eines Datensatzes. Als erstes musste ich die Texte zur weiteren Verarbeitung durch die Maschine vorbereiten.</p> <p>In einem ersten Schritt anonymisiert das Programm Benutzernamen, falls das nicht bereits in den Quell-Datensätzen geschehen ist. Zudem werden Elemente entfernt, die nichts direkt mit dem untersuchten Text zu tun haben, beispielsweise Links oder plattformspezifische Ausdrücke wie RT (Hinweis auf einen Retweet bei Twitter). Diese Elemente würden ansonsten das Resultat verzerren.</p> <p>In einem weiteren Schritt entferne ich «Stopwords» aus dem Text. <a href="https://en.wikipedia.org/wiki/Stop_words" target="_blank" rel="noopener noreferrer">Stopwords<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> sind Wörter, die in einer Sprache oft vorkommen, aber wenig zur Aussage eines Satzes beitragen, beispielsweise «der», «das», «ein», etc. Anschliessend benutzte ich einen <a href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" target="_blank" rel="noopener noreferrer">Lemmatizer<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, um Wörter auf ihre Grundform zu reduzieren. Konjugierte Verben werden so als dasselbe Wort angesehen, also beispielsweise «bin», «bist» und «sind» werden in dieselbe Grundform «sein» umgewandelt.</p> <ul><li><a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/0_common/model_helpers.py" target="_blank" rel="noopener noreferrer">Code der Umwandlung<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <p>Der wichtigste Schritt in der maschinellen Sprachverarbeitung ist das Vektorisieren, also die Umwandlung von Buchstaben in Zahlen. Dies ist nötig, weil Computer nicht mit Worten oder Buchstaben rechnen, sondern mit Zahlen. Dafür gibt es verschiedene Methoden. Während der Entwicklung meines Machine Learning Modells habe ich verschiedene Verfahren ausprobiert. Schlussendlich habe ich mit einem simplen <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" target="_blank" rel="noopener noreferrer">CountVectorizer<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> auf der Basis von Wortteilen die besten Resultate erzielt. Diese Erfahrung findet sich auch in der Wissenschaft wieder, beispielsweise bei Schmidt und Wiegand (2017, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" target="_blank" rel="noopener noreferrer">Link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>). Wortteile, anstelle von ganzen Wörtern, bringen eine gewisse Toleranz gegenüber Rechtschreibefehlern mit sich. Das ist durchaus ein Vorteil, da Hater scheinbar Mühe haben mit korrektem Sprachgebrauch.</p> <p>Zudem suchte ich nach zusätzlichen Merkmalen, die eine bessere Unterscheidung in die beiden Klassen ermöglicht hätten. Im Ordner <a href="https://github.com/pscllbssr/hatespeech-ml/tree/master/2_Feature_Engineering" target="_blank" rel="noopener noreferrer">Feature-Engineering<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> sind die verschiedenen Versuche abgelegt. Keines der zusätzlichen Merkmale (Textlänge, Anzahl Satzzeichen, Sentiment-Analyse, Anteil Fluchwörter im Text) liess jedoch einen erheblichen Unterschied zwischen neutralen und hasserfüllten Kommentaren erkennen.</p> <h2 id="auswahl-der-algorithmen-und-modell-training"><a href="#auswahl-der-algorithmen-und-modell-training" aria-hidden="true" class="header-anchor"></a> Auswahl der Algorithmen und Modell-Training</h2> <p>Schlussendlich galt es einen geeigneten Machine Learning Algorithmus auszuwählen. Dazu verglich ich die gängigsten Algorithmen anhand des <a href="https://www.mikulskibartosz.name/f1-score-explained/" target="_blank" rel="noopener noreferrer">F1-Scores<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, einer gängigen Metrik im Machine Learning Bereich (<a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/3_Model_Development/5_Version/6%20Evaluation%20of%20Algorithms%20with%20large%20dataset.ipynb" target="_blank" rel="noopener noreferrer">Jupyter-Notebook<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>). Dabei schnitt die <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" target="_blank" rel="noopener noreferrer">logistische Regression<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> am besten ab, dicht gefolgt von <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" target="_blank" rel="noopener noreferrer">Decision Trees<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> und dem <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" target="_blank" rel="noopener noreferrer">Random Forest Classifier<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</p> <p>Anschliessend verglich ich die logistische Regression und den Random Forest weiter mit verschiedenen Einstellungen (<a href="https://www.twt.de/news/detail/hyperparameter-tuning-der-feinschliff-eines-machine-learning-modells.html" target="_blank" rel="noopener noreferrer">«Hyperparameter»<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>). Den Decision Tree Classifier liess ich aus, weil er gegenüber Random Forest nicht so anfällig ist für «Overfitting» (<a href="https://towardsdatascience.com/why-random-forests-outperform-decision-trees-1b0f175a0b5" target="_blank" rel="noopener noreferrer">Erläuterung<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>). Overfitting bedeutet, dass ein Algorithmus zu gut auf einen Datensatz trainiert ist, sich beispielsweise unbedeutende Artefakte merkt, jedoch kaum auf generelle Beispiele angewendet werden kann.</p> <p>Die besten Resultate lieferte schliesslich der Random Forest Algorithmus, mit einem <strong>F1-Score von 91.9%</strong> und einem <strong>Recall-Wert von 92.9%</strong>.</p> <ul><li><a href="https://github.com/pscllbssr/hatespeech-ml/blob/master/3_Model_Development/7_Version%20Deployment/4%20RF%20with%20char-vec.ipynb" target="_blank" rel="noopener noreferrer">Jupyter-Notebook<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> des finalen Modells</li></ul> <h2 id="deployment"><a href="#deployment" aria-hidden="true" class="header-anchor"></a> Deployment</h2> <p>Um das Modell im Internet nutzen zu können, musste ich das trainierte Modell exportieren und in eine Schnittstelle verpacken. Für die Schnittstelle griff ich auf das <a href="https://github.com/pallets/flask" target="_blank" rel="noopener noreferrer">Flask-Framework<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> zurück, das in der gleichen Programmiersprache geschrieben ist wie der Machine Learning Code (Python). So konnte ich das Modell ohne weitere Umschweife einbinden und eine Abfrage programmieren, die einen Text als Eingabe entgegen nimmt und die Einschätzung des Modells als Resultat ausgibt. Der Code für die Schnittstelle ist auch auf <a href="https://github.com/pscllbssr/hatespeech-api" target="_blank" rel="noopener noreferrer">Github<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> verfügbar.</p> <h2 id="weitervewerwendung"><a href="#weitervewerwendung" aria-hidden="true" class="header-anchor"></a> Weitervewerwendung</h2> <p>Sämtlicher Code ist frei verfügbar und darf gerne weiterverwendet werden. Für eine allfällige Weiterentiwcklung des Modells oder eine Integration der Schnittstelle bin ich unter <a href="mailto:pscl.lbssr@gmail.com">pscl.lbssr@gmail.com</a> erreichbar. Ein Beispiel für die Einbindung der Schnittstelle mit Javascript findet sich im <a href="https://github.com/pscllbssr/hatespeech-frontend/blob/master/docs/.vuepress/components/HateForm.vue" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> dieser Webseite.</p> <div class="section-element center-box"><p><a href="/der-hass-im-netz/" class="router-link-active">← Zurück zum Artikel</a></p></div> <div class="section-element info-box"><h2 id="info"><a href="#info" aria-hidden="true" class="header-anchor"></a> Info</h2> <p>Dieser Artikel ist Teil meiner Bachelorarbeit im Studiengang «Media Engineering» an der HTW Chur. In der begleitenden wissenschaftlichen Arbeit habe ich mich mit der Frage beschäftigt, inwiefern Machine Learning in der journalistischen Recherche eine Rolle spielen kann. Für Fragen, Anregungen und Kritik bin ich unter der Adresse <a href="mailto:pscl.lbssr@gmail.com">pscl.lbssr@gmail.com</a> erreichbar.</p> <ul><li><a href="https://pscl.lbssr.ch" target="_blank" rel="noopener noreferrer">Webseite<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><br></li> <li><a href="https://github.com/pscllbssr" target="_blank" rel="noopener noreferrer">Github<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><br></li> <li><a href="https://www.linkedin.com/in/pascal-albisser" target="_blank" rel="noopener noreferrer">LinkedIn<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><br></li></ul></div></div></div></div></div>
    <script src="/der-hass-im-netz/assets/js/app.12741693.js" defer></script><script src="/der-hass-im-netz/assets/js/2.71482812.js" defer></script><script src="/der-hass-im-netz/assets/js/7.5ffeac9c.js" defer></script>
  </body>
</html>
